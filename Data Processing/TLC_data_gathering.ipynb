{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f8a897",
   "metadata": {
    "id": "00f8a897"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Marko\\\\Documents\\\\school\\\\IST707_AppliedML\\\\final_project'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# os.chdir(r'C:\\Users\\mmasniko\\OneDrive - Syracuse University\\Documents\\SU\\Spring25\\IST707\\final_project')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bc5e0-95d2-4185-8fd0-7f99164f9ece",
   "metadata": {},
   "source": [
    "# Data scoping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9ca3a",
   "metadata": {
    "id": "90b9ca3a"
   },
   "outputs": [],
   "source": [
    "# Data from: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "\n",
    "# df_yellow_cab = pd.read_parquet('data/yellow_tripdata_2020-01.parquet', engine='pyarrow')\n",
    "# df_yellow_cab.head()\n",
    "\n",
    "# multiple trips per day\n",
    "# columns:\n",
    "# passenger count\n",
    "# trip_distance\n",
    "# rate code id\n",
    "# store and fwd flag\n",
    "# PU location id\n",
    "# DO location id\n",
    "# payment type\n",
    "# fare amount\n",
    "# extra\n",
    "# mta tax\n",
    "# tip amount\n",
    "# tolls amount\n",
    "# improvement surcharge\n",
    "# total amount\n",
    "# congestion surcharge\n",
    "# airport fee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390cefd",
   "metadata": {
    "id": "e390cefd",
    "outputId": "67457ca9-a2d1-4027-c2ab-e902649a9690"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-18 15:52:30</td>\n",
       "      <td>2019-12-18 15:54:39</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 00:45:58</td>\n",
       "      <td>2020-01-01 00:56:39</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 00:41:38</td>\n",
       "      <td>2020-01-01 00:52:49</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181</td>\n",
       "      <td>228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.47</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 00:52:46</td>\n",
       "      <td>2020-01-01 01:14:21</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129</td>\n",
       "      <td>263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 00:19:57</td>\n",
       "      <td>2020-01-01 00:30:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2019-12-18 15:52:30   2019-12-18 15:54:39                  N   \n",
       "1         2  2020-01-01 00:45:58   2020-01-01 00:56:39                  N   \n",
       "2         2  2020-01-01 00:41:38   2020-01-01 00:52:49                  N   \n",
       "3         1  2020-01-01 00:52:46   2020-01-01 01:14:21                  N   \n",
       "4         1  2020-01-01 00:19:57   2020-01-01 00:30:56                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0           264           264              5.0           0.00   \n",
       "1         5.0            66            65              2.0           1.28   \n",
       "2         1.0           181           228              1.0           2.47   \n",
       "3         1.0           129           263              2.0           6.30   \n",
       "4         1.0           210           150              1.0           2.30   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
       "0          3.5   0.50      0.5        0.01           0.0      None   \n",
       "1         20.0   0.00      0.0        4.06           0.0      None   \n",
       "2         10.5   0.50      0.5        3.54           0.0      None   \n",
       "3         21.0   3.25      0.5        0.00           0.0      None   \n",
       "4         10.0   0.50      0.5        0.00           0.0      None   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          4.81           1.0        1.0   \n",
       "1                    0.3         24.36           1.0        2.0   \n",
       "2                    0.3         15.34           1.0        1.0   \n",
       "3                    0.3         25.05           2.0        1.0   \n",
       "4                    0.3         11.30           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  0.00  \n",
       "2                  0.00  \n",
       "3                  2.75  \n",
       "4                  0.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_green_cab = pd.read_parquet('data/green_tripdata_2020-01.parquet', engine = 'pyarrow')\n",
    "# df_green_cab.head()\n",
    "\n",
    "# mutiple trips per day\n",
    "# columns:\n",
    "# store and fwd flag\n",
    "# rate code id\n",
    "# PU location id\n",
    "# DO location id\n",
    "# passanger count\n",
    "# trip distance\n",
    "# fare amount\n",
    "# extra\n",
    "# mta tax\n",
    "# tip amount\n",
    "# tolls amount\n",
    "# ehail fee\n",
    "# improvement surcharge\n",
    "# total amount\n",
    "# payment type\n",
    "# trip type\n",
    "# congestion surcharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1e024",
   "metadata": {
    "id": "47f1e024",
    "outputId": "2139b13a-8e6c-41b4-9385-01e86318a820"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2020-01-01 00:30:00</td>\n",
       "      <td>2020-01-01 01:44:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2020-01-01 00:30:00</td>\n",
       "      <td>2020-01-01 00:47:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2020-01-01 00:48:00</td>\n",
       "      <td>2020-01-01 01:19:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2020-01-01 00:34:00</td>\n",
       "      <td>2020-01-01 00:43:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2020-01-01 00:23:00</td>\n",
       "      <td>2020-01-01 00:32:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00001 2020-01-01 00:30:00 2020-01-01 01:44:00         264.0   \n",
       "1               B00001 2020-01-01 00:30:00 2020-01-01 00:47:00         264.0   \n",
       "2               B00009 2020-01-01 00:48:00 2020-01-01 01:19:00         264.0   \n",
       "3               B00009 2020-01-01 00:34:00 2020-01-01 00:43:00         264.0   \n",
       "4               B00009 2020-01-01 00:23:00 2020-01-01 00:32:00         264.0   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0         264.0    None                 B00001  \n",
       "1         264.0    None                 B00001  \n",
       "2         264.0    None                 B00009  \n",
       "3         264.0    None                 B00009  \n",
       "4         264.0    None                 B00009  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_fhv = pd.read_parquet('data/fhv_tripdata_2020-01.parquet', engine = 'pyarrow')\n",
    "# df_fhv.head()\n",
    "\n",
    "# multiple trips per day\n",
    "# columns:\n",
    "# dispatching base num\n",
    "# PU location\n",
    "# DO location\n",
    "# SR flag\n",
    "# affiliated base num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cf457",
   "metadata": {
    "id": "332cf457",
    "outputId": "f0931318-5be3-4522-8c17-7e8ee8e089e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-01 00:40:13</td>\n",
       "      <td>2020-01-01 00:45:34</td>\n",
       "      <td>2020-01-01 01:02:20</td>\n",
       "      <td>148</td>\n",
       "      <td>90</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1006</td>\n",
       "      <td>30.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.25</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-01 00:42:31</td>\n",
       "      <td>2020-01-01 00:47:50</td>\n",
       "      <td>2020-01-01 00:53:23</td>\n",
       "      <td>114</td>\n",
       "      <td>79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>333</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-01 00:01:42</td>\n",
       "      <td>2020-01-01 00:04:37</td>\n",
       "      <td>2020-01-01 00:21:49</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1032</td>\n",
       "      <td>15.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.73</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-01 00:21:23</td>\n",
       "      <td>2020-01-01 00:26:36</td>\n",
       "      <td>2020-01-01 00:33:00</td>\n",
       "      <td>231</td>\n",
       "      <td>113</td>\n",
       "      <td>1.11</td>\n",
       "      <td>384</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-01 00:32:20</td>\n",
       "      <td>2020-01-01 00:37:49</td>\n",
       "      <td>2020-01-01 00:46:59</td>\n",
       "      <td>114</td>\n",
       "      <td>144</td>\n",
       "      <td>1.10</td>\n",
       "      <td>550</td>\n",
       "      <td>11.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.03</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.69</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num    request_datetime     pickup_datetime  \\\n",
       "0            HV0003 2020-01-01 00:40:13 2020-01-01 00:45:34   \n",
       "1            HV0003 2020-01-01 00:42:31 2020-01-01 00:47:50   \n",
       "2            HV0003 2020-01-01 00:01:42 2020-01-01 00:04:37   \n",
       "3            HV0003 2020-01-01 00:21:23 2020-01-01 00:26:36   \n",
       "4            HV0003 2020-01-01 00:32:20 2020-01-01 00:37:49   \n",
       "\n",
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  trip_time  \\\n",
       "0 2020-01-01 01:02:20           148            90        1.93       1006   \n",
       "1 2020-01-01 00:53:23           114            79        0.81        333   \n",
       "2 2020-01-01 00:21:49             4           125        2.53       1032   \n",
       "3 2020-01-01 00:33:00           231           113        1.11        384   \n",
       "4 2020-01-01 00:46:59           114           144        1.10        550   \n",
       "\n",
       "   base_passenger_fare  tolls   bcf  sales_tax  congestion_surcharge  tips  \\\n",
       "0                30.44    0.0  0.76       2.70                  2.75   0.0   \n",
       "1                14.80    0.0  0.37       1.31                  2.75   0.0   \n",
       "2                15.63    0.0  0.47       1.39                  2.75   3.0   \n",
       "3                 8.44    0.0  0.21       0.75                  2.75   0.0   \n",
       "4                11.57    0.0  0.29       1.03                  2.75   0.0   \n",
       "\n",
       "   driver_pay shared_request_flag shared_match_flag  \n",
       "0       18.25                   N                 N  \n",
       "1       10.84                   N                 N  \n",
       "2       11.73                   N                 N  \n",
       "3        5.84                   N                 N  \n",
       "4        7.69                   N                 N  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High Volume for-hire vehicles\n",
    "## DATA FILES ARE VERY LARGE\n",
    "\n",
    "df_hvfhv = pd.read_parquet('data/fhvhv_tripdata_2020-01.parquet', engine = 'pyarrow')\n",
    "df_hvfhv = df_hvfhv[df_hvfhv.hvfhs_license_num.isin(['HV0003', 'HV0005'])] # only include Uber and Lyft\n",
    "df_hvfhv.drop(columns = ['airport_fee', 'on_scene_datetime', 'originating_base_num',\n",
    "                         'wav_request_flag', 'wav_match_flag', 'access_a_ride_flag',\n",
    "                        'dispatching_base_num'], inplace=True)\n",
    "df_hvfhv.head()\n",
    "\n",
    "# multiple trips per day\n",
    "\n",
    "# columns:\n",
    "# HVFHV license num # Rideshare app company\n",
    "\n",
    "# request date: date/time when passenger requested to be picked up\n",
    "# PU date: The date and time of the trip pick-up\n",
    "# DO date: The date and time of the trip drop-off\n",
    "# PU location: TLC Taxi Zone in which the trip began\n",
    "# DO location: TLC Taxi Zone in which the trip ended\n",
    "# trip miles: total miles for passenger trip\n",
    "# trip time: total time in seconds for passenger trip\n",
    "# base passenger fare: base passenger fare before tolls, tips, taxes, and fees\n",
    "# tolls: total amount of all tolls paid in trip\n",
    "# bcf: total amount collected in trip for Black Car Fund\n",
    "# sales tax: total amount collected in trip for NYS sales tax\n",
    "# congestion surcharge: total amount collected in trip for NYS congestion surcharge\n",
    "# tips: total amount of tips received from passenger\n",
    "# driver pay: total driver pay (not including tolls or tips and net of commission, surcharges, or taxes)\n",
    "# shared request flag: Did the passenger agree to a shared/pooled ride\n",
    "# shared match flag # Did the passenger share the vehicle with another passenger who booked separately at any point during the trip?\n",
    "\n",
    "# Dropped columns:\n",
    "# dispatching base num # The TLC Base License Number of the base that dispatched the trip, not needed for analysis\n",
    "# originating base num # mostly nulls, will be dropped\n",
    "# on scene date # mostly nulls, will be dropped\n",
    "# airport fee # mostly nulls, will be dropped\n",
    "# access a ride flag # mostly blank space instead of indicator Y/N. Assuming this is missing, dropping feature\n",
    "# wav request flag: wheelchair accessible vehicle request: drop\n",
    "# wav match flag: wheelchair accessible vehicle match: drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f098e",
   "metadata": {
    "id": "1e7f098e",
    "outputId": "5b55e5d9-e15a-4ac8-a00b-769af2ad621f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19856768 entries, 0 to 20569367\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   hvfhs_license_num     object        \n",
      " 1   request_datetime      datetime64[us]\n",
      " 2   pickup_datetime       datetime64[us]\n",
      " 3   dropoff_datetime      datetime64[us]\n",
      " 4   PULocationID          int64         \n",
      " 5   DOLocationID          int64         \n",
      " 6   trip_miles            float64       \n",
      " 7   trip_time             int64         \n",
      " 8   base_passenger_fare   float64       \n",
      " 9   tolls                 float64       \n",
      " 10  bcf                   float64       \n",
      " 11  sales_tax             float64       \n",
      " 12  congestion_surcharge  float64       \n",
      " 13  tips                  float64       \n",
      " 14  driver_pay            float64       \n",
      " 15  shared_request_flag   object        \n",
      " 16  shared_match_flag     object        \n",
      "dtypes: datetime64[us](3), float64(8), int64(3), object(3)\n",
      "memory usage: 2.7+ GB\n"
     ]
    }
   ],
   "source": [
    "df_hvfhv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db3d07",
   "metadata": {
    "id": "17db3d07",
    "outputId": "2782c93f-020e-455b-be0f-238570894304"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HV0003', 'HV0005', 'HV0004'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hvfhv.hvfhs_license_num.unique()\n",
    "# HV0003: Uber\n",
    "# HV0004: Via\n",
    "# HV0005: Lyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb0b40",
   "metadata": {
    "id": "abdb0b40"
   },
   "outputs": [],
   "source": [
    "app_dict = {'HV0003':'Uber', 'HV0005':'Lyft'}\n",
    "df_hvfhv['app'] = df_hvfhv['hvfhs_license_num'].replace(app_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1f66b8",
   "metadata": {
    "id": "af1f66b8"
   },
   "outputs": [],
   "source": [
    "def agg_get_count(X):\n",
    "    \"\"\" Hourly count of trips\n",
    "    \"\"\"\n",
    "    count_result = X.groupby(['pickup_date', 'pickup_hour'])['pickup_datetime'].count().reset_index()\n",
    "    count_result.rename(columns = {'pickup_datetime': 'trip_count'}, inplace = True)\n",
    "    return count_result\n",
    "\n",
    "def agg_get_mode(X, feature):\n",
    "    \"\"\" aggregates the feature of dataframe X by date and hour of day to most frequent\n",
    "    \"\"\"\n",
    "#     return X.groupby(['pickup_date','pickup_hour'])[feature].agg(lambda x: x.mode()[0]).reset_index()\n",
    "    mode_result = X.groupby(['pickup_date', 'pickup_hour'])[feature].agg(lambda x: x.mode()[0]).reset_index()\n",
    "    mode_result.rename(columns={feature: f'{feature}_mode'}, inplace=True)\n",
    "    return mode_result\n",
    "\n",
    "\n",
    "def agg_mean_sum(X, feature):\n",
    "    \"\"\" aggregates the feature of dataframe X by date and hour of day to mean and sum\n",
    "    \"\"\"\n",
    "#     return X.groupby(['pickup_date','pickup_hour']).agg(Mean=(feature, np.mean), Sum=(feature, np.sum)).reset_index()\n",
    "    aggregated_result = X.groupby(['pickup_date','pickup_hour']).agg(\n",
    "        **{f'{feature}_mean':(feature, np.mean),\n",
    "           f'{feature}_sum':(feature, np.sum)}).reset_index()\n",
    "    return aggregated_result\n",
    "\n",
    "# Define a function to compute aggregations for a given dataframe\n",
    "def compute_aggregations(df):\n",
    "    return {\n",
    "        \"cnt\": agg_get_count(df),\n",
    "        \"pul\": agg_get_mode(df, \"PULocationID\"),\n",
    "        \"dol\": agg_get_mode(df, \"DOLocationID\"),\n",
    "        \"wke\": agg_get_mode(df, \"is_weekend\"),\n",
    "        \"trip_distance\": agg_mean_sum(df, \"trip_miles\"),\n",
    "        \"trip_time\": agg_mean_sum(df, \"trip_time\"),\n",
    "        \"base_fare\": agg_mean_sum(df, \"base_passenger_fare\"),\n",
    "        \"tolls\": agg_mean_sum(df, \"tolls\"),\n",
    "        \"bcf\": agg_mean_sum(df, \"bcf\"),\n",
    "        \"sales_tax\": agg_mean_sum(df, \"sales_tax\"),\n",
    "        \"congestion_surcharge\": agg_mean_sum(df, \"congestion_surcharge\"),\n",
    "        \"tips\": agg_mean_sum(df, \"tips\"),\n",
    "        \"driver_pay\": agg_mean_sum(df, \"driver_pay\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b909c9-0328-41a1-aea2-e4b76b62e70b",
   "metadata": {},
   "source": [
    "# 2020 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397dff2",
   "metadata": {
    "id": "f397dff2",
    "outputId": "fb355650-9b07-43ed-acf2-846189c7b29f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lyft</th>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "      <td>5274248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uber</th>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "      <td>14582520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hvfhs_license_num  request_datetime  pickup_datetime  dropoff_datetime  \\\n",
       "app                                                                            \n",
       "Lyft            5274248           5274248          5274248           5274248   \n",
       "Uber           14582520          14582520         14582520          14582520   \n",
       "\n",
       "      PULocationID  DOLocationID  trip_miles  trip_time  base_passenger_fare  \\\n",
       "app                                                                            \n",
       "Lyft       5274248       5274248     5274248    5274248              5274248   \n",
       "Uber      14582520      14582520    14582520   14582520             14582520   \n",
       "\n",
       "         tolls       bcf  sales_tax  congestion_surcharge      tips  \\\n",
       "app                                                                   \n",
       "Lyft   5274248   5274248    5274248               5274248   5274248   \n",
       "Uber  14582520  14582520   14582520              14582520  14582520   \n",
       "\n",
       "      driver_pay  shared_request_flag  shared_match_flag  \n",
       "app                                                       \n",
       "Lyft     5274248              5274248            5274248  \n",
       "Uber    14582520             14582520           14582520  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hvfhv.groupby('app').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e17d96",
   "metadata": {
    "id": "95e17d96",
    "outputId": "e1ecce1c-5a21-4903-ed94-a26c9a9a3d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shared_request_flag\n",
       "N    0.848122\n",
       "Y    0.151878\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hvfhv.shared_request_flag.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04491c4",
   "metadata": {
    "id": "d04491c4",
    "outputId": "1c6ffc45-c400-4273-aaa2-633b2276c1f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shared_match_flag\n",
       "N    0.91224\n",
       "Y    0.08776\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hvfhv.shared_match_flag.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8303818",
   "metadata": {
    "id": "f8303818"
   },
   "outputs": [],
   "source": [
    "df_uber = df_hvfhv[df_hvfhv.app == 'Uber']\n",
    "df_lyft = df_hvfhv[df_hvfhv.app == 'Lyft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f0eb8",
   "metadata": {
    "id": "274f0eb8",
    "outputId": "b19a04f4-2a75-4d5a-d280-e9ead804a7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uber: 0 days 00:04:09.255715\n",
      "lyft: 0 days 00:04:30.197747\n",
      "avg: 0 days 00:04:14.818225\n"
     ]
    }
   ],
   "source": [
    "print('uber:', (df_uber.pickup_datetime - df_uber.request_datetime).mean())\n",
    "print('lyft:', (df_lyft.pickup_datetime - df_lyft.request_datetime).mean())\n",
    "print('avg:', (df_hvfhv.pickup_datetime - df_hvfhv.request_datetime).mean()) # Average wait time from request to pickup is 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c000f26",
   "metadata": {
    "id": "2c000f26",
    "outputId": "593db033-c143-4fe5-b8c7-716a01397d9f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PULocationID\n",
       "132    238551\n",
       "138    228697\n",
       "61     208998\n",
       "79     197254\n",
       "161    176780\n",
       "        ...  \n",
       "110        13\n",
       "1           9\n",
       "2           9\n",
       "105         3\n",
       "199         1\n",
       "Name: count, Length: 262, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uber['PULocationID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f5a8e",
   "metadata": {
    "id": "344f5a8e",
    "outputId": "9de5d909-5f14-4e37-871c-fea7e3744eea",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOLocationID\n",
       "265    421501\n",
       "132    256563\n",
       "138    225263\n",
       "61     215957\n",
       "79     171799\n",
       "        ...  \n",
       "8         296\n",
       "110        19\n",
       "2          16\n",
       "105         6\n",
       "199         1\n",
       "Name: count, Length: 262, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uber['DOLocationID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b890990",
   "metadata": {
    "id": "3b890990",
    "outputId": "6db35530-ac18-4d63-a6dd-b8411fc7e193"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shared_request_flag\n",
       "N    0.883699\n",
       "Y    0.116301\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uber['shared_request_flag'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeeb90d8",
   "metadata": {
    "id": "eeeb90d8",
    "outputId": "cf132a13-130a-4652-dba2-041043ea6cb0",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_hvfhv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_hvfhv\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_hvfhv' is not defined"
     ]
    }
   ],
   "source": [
    "df_hvfhv.head(3)\n",
    "\n",
    "# to aggregate to hourly\n",
    "# group by uber/lyft\n",
    "# count trips per hour\n",
    "# request_datetime: drop\n",
    "# pickup_datetime: extract hour of day\n",
    "# dropoff_datetime: drop?\n",
    "# PULocationID: location with the most pickups that hour\n",
    "# DOLocationID: location with the most dropoffs that hour\n",
    "# trip miles: sum per hour\n",
    "# trip_miles: average per hour\n",
    "# trip_time: sum per hour\n",
    "# trip_time: average per hour\n",
    "# base_passenger_fare: sum per hour\n",
    "# base_passenger_fare: average per hour\n",
    "# tolls: sum per hour\n",
    "# tolls: average per hour\n",
    "# bcf: average per hour\n",
    "# sales tax: average per hour\n",
    "# congestion_surcharge: sum per hour\n",
    "# congestion_surcharge: average per hour\n",
    "# tips: sum per hour\n",
    "# tips: average per hour\n",
    "# driver_pay: average per hour\n",
    "# shared_request_flag: most frequent value per hour: drop\n",
    "# shared_match_flag: most frequent value per hour: drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b453c17",
   "metadata": {
    "id": "9b453c17"
   },
   "outputs": [],
   "source": [
    "# about 3 million rows where the passanger base fare, surcharges, and sales tax were less than driver pay.\n",
    "# Driver pay does not include tips according to the data dictionary. These rows don't add up so they will be dropped\n",
    "df_uber = df_uber[(df_uber.base_passenger_fare + df_uber.congestion_surcharge + df_uber.sales_tax) > df_uber.driver_pay]\n",
    "\n",
    "# about 151k rows where the pay doesnt add up\n",
    "df_lyft = df_lyft[(df_lyft.base_passenger_fare + df_lyft.congestion_surcharge + df_lyft.sales_tax) > df_lyft.driver_pay]\n",
    "\n",
    "# About 3 million rows were dropped after that cleaning\n",
    "pd.concat([df_uber, df_lyft], axis=0).shape[0] - df_hvfhv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edf0e0",
   "metadata": {
    "id": "10edf0e0"
   },
   "outputs": [],
   "source": [
    "# define the columns to be used for grouping\n",
    "df_uber['pickup_hour'] = df_uber['pickup_datetime'].dt.hour\n",
    "df_uber['pickup_date'] = df_uber['pickup_datetime'].dt.date\n",
    "\n",
    "# flag to indicate it the pickup date was on a weekend, monday = 0, sunday = 6\n",
    "df_uber['is_weekend'] = df_uber['pickup_datetime'].dt.weekday > 5\n",
    "\n",
    "df_lyft['pickup_hour'] = df_lyft['pickup_datetime'].dt.hour\n",
    "df_lyft['pickup_date'] = df_lyft['pickup_datetime'].dt.date\n",
    "df_lyft['is_weekend'] = df_lyft['pickup_datetime'].dt.weekday > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a551722-6926-4ce4-94cd-27ca68edc030",
   "metadata": {
    "id": "6a96280a"
   },
   "outputs": [],
   "source": [
    "# Compute aggregations for Uber and Lyft\n",
    "uber_aggregations = compute_aggregations(df_uber)\n",
    "lyft_aggregations = compute_aggregations(df_lyft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040044af",
   "metadata": {
    "id": "040044af"
   },
   "outputs": [],
   "source": [
    "# build a dataframe to merge the aggregate values to\n",
    "uber_hourly_df = pd.DataFrame(uber_aggregations['cnt'][['pickup_date', 'pickup_hour']])\n",
    "for v in uber_aggregations.values():\n",
    "    uber_hourly_df = uber_hourly_df.merge(v, on = ['pickup_date', 'pickup_hour'])\n",
    "\n",
    "lyft_hourly_df = pd.DataFrame(lyft_aggregations['cnt'][['pickup_date', 'pickup_hour']])\n",
    "for v in lyft_aggregations.values():\n",
    "    lyft_hourly_df = lyft_hourly_df.merge(v, on = ['pickup_date', 'pickup_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307d231",
   "metadata": {
    "id": "5307d231"
   },
   "outputs": [],
   "source": [
    "# save to disk\n",
    "# uber_hourly_df.to_csv('data/hourly/uber_hourly1.csv', index=False)\n",
    "# lyft_hourly_df.to_csv('data/hourly/lyft_hourly1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffbd008-dba8-406d-af65-fe415a4a1d7d",
   "metadata": {},
   "source": [
    "# Scripted processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04c7de1a-eefc-4239-91d8-1782d3be6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_hourly(path_to_raw, year, start=1, end=13):\n",
    "    \"\"\"\n",
    "    This function will take parquet files of a certain format 'fhvhv_trip_data_%yyyy-%mm.parquet'\n",
    "      and apply preprocessing to aggregate trip level data to an hourly level. \n",
    "    Args:\n",
    "        path_to_raw (str): The base directory containing the parquet files.\n",
    "        year (int or str): The year to process (e.g., 2020 or '2020').\n",
    "        start (int): The starting month (inclusive).\n",
    "        end (int): The ending month (exclusive).\n",
    "    \"\"\"\n",
    "    app_dict = {'HV0003':'Uber', 'HV0005':'Lyft'}\n",
    "    year = str(year)  # Ensure year is a string for consistent formatting\n",
    "    \n",
    "    # for i in range(start,end):\n",
    "    #     # Read data\n",
    "    #     if i < 10:\n",
    "    #         # df_hv = pd.read_parquet(f'data/high_volume_raw/fhvhv_tripdata_2020-0{i}.parquet', engine = 'pyarrow')\n",
    "    #         df_hv = pd.read_parquet(f'{path_to_raw}fhvhv_tripdata_{year}_-0{i}.parquet', engine = 'pyarrow')\n",
    "    #     else:\n",
    "    #         # df_hv = pd.read_parquet(f'data/high_volume_raw/fhvhv_tripdata_2020-{i}.parquet', engine = 'pyarrow')\n",
    "    #         df_hv = pd.read_parquet(f'{path_to_raw}fhvhv_tripdata_{year}_-{i}.parquet', engine = 'pyarrow')\n",
    "\n",
    "    for month in range(start, end):\n",
    "        month_str = f'{month:02}'  # Format month with leading zero if needed\n",
    "\n",
    "        # Construct the file path\n",
    "        file_name = f'fhvhv_tripdata_{year}-{month_str}.parquet'\n",
    "        file_path = os.path.join(path_to_raw, file_name)\n",
    "\n",
    "        try:\n",
    "            # Read data\n",
    "            df_hv = pd.read_parquet(file_path, engine='pyarrow')\n",
    "             \n",
    "            # only include Uber and Lyft\n",
    "            df_hv = df_hv[df_hv.hvfhs_license_num.isin(['HV0003', 'HV0005'])] \n",
    "            \n",
    "            # Drop columns that are mostly empty\n",
    "            df_hv.drop(columns = ['airport_fee', 'on_scene_datetime', 'originating_base_num', \n",
    "                                 'wav_request_flag', 'wav_match_flag', 'access_a_ride_flag',\n",
    "                                'dispatching_base_num'], inplace=True)\n",
    "            \n",
    "            # get the app associated with the license number\n",
    "            df_hv['app'] = df_hv['hvfhs_license_num'].replace(app_dict)\n",
    "            df_uber_hv = df_hv[df_hv.app == 'Uber']\n",
    "            df_lyft_hv = df_hv[df_hv.app == 'Lyft']\n",
    "            \n",
    "            # Drop rows where the driver pay is greater than overall charge somehow\n",
    "            df_uber_hv = df_uber_hv[(df_uber_hv.base_passenger_fare + df_uber_hv.congestion_surcharge + df_uber_hv.sales_tax) > df_uber_hv.driver_pay]\n",
    "            df_lyft_hv = df_lyft_hv[(df_lyft_hv.base_passenger_fare + df_lyft_hv.congestion_surcharge + df_lyft_hv.sales_tax) > df_lyft_hv.driver_pay]\n",
    "            print(f\"Num rows dropped for dataset {month}: \", (df_uber_hv.shape[0] +  df_lyft_hv.shape[0]) - df_hv.shape[0])\n",
    "            \n",
    "            ## define the columns to be used for grouping\n",
    "            df_uber_hv['pickup_hour'] = df_uber_hv['pickup_datetime'].dt.hour\n",
    "            df_uber_hv['pickup_date'] = df_uber_hv['pickup_datetime'].dt.date\n",
    "            ## flag to indicate it the pickup date was on a weekend, monday = 0, sunday = 6\n",
    "            df_uber_hv['is_weekend'] = df_uber_hv['pickup_datetime'].dt.weekday > 5\n",
    "    \n",
    "            df_lyft_hv['pickup_hour'] = df_lyft_hv['pickup_datetime'].dt.hour\n",
    "            df_lyft_hv['pickup_date'] = df_lyft_hv['pickup_datetime'].dt.date\n",
    "            df_lyft_hv['is_weekend'] = df_lyft_hv['pickup_datetime'].dt.weekday > 5\n",
    "            \n",
    "            uber_aggregations = compute_aggregations(df_uber_hv)\n",
    "            lyft_aggregations = compute_aggregations(df_lyft_hv)\n",
    "            \n",
    "            ## build a dataframe to merge the aggregate values to\n",
    "            uber_hourly_df = pd.DataFrame(uber_aggregations['cnt'][['pickup_date', 'pickup_hour']])\n",
    "            for v in uber_aggregations.values():\n",
    "                uber_hourly_df = uber_hourly_df.merge(v, on = ['pickup_date', 'pickup_hour'])\n",
    "    \n",
    "            lyft_hourly_df = pd.DataFrame(lyft_aggregations['cnt'][['pickup_date', 'pickup_hour']])\n",
    "            for v in lyft_aggregations.values():\n",
    "                lyft_hourly_df = lyft_hourly_df.merge(v, on = ['pickup_date', 'pickup_hour'])\n",
    "            \n",
    "            ## save to disk\n",
    "            uber_hourly_df.to_csv(f'data/hourly/uber_hourly_{year}_{month}.csv', index=False)\n",
    "            lyft_hourly_df.to_csv(f'data/hourly/lyft_hourly_{year}_{month}.csv', index=False)\n",
    "            print(f\"Saved to disk {month}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "                print(f\"Warning: File not found - {file_name}\")\n",
    "    \n",
    "        except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fc24d5f-5262-4d63-87f1-7b3549eb56d4",
   "metadata": {
    "id": "dM6xjZ9fQZH1"
   },
   "outputs": [],
   "source": [
    "def combine_hourly_data(path_to_hourly, app, year):\n",
    "    \"\"\"\n",
    "    Data is saved in separate files, one per month (1-12), and split between uber and lyft data (app).\n",
    "    This combines the monthly data that has already been aggregated to the hourly level.\n",
    "    \"\"\"\n",
    "\n",
    "    year = str(year)  # Ensure year is a string for consistent formatting\n",
    "    dataframes = []\n",
    "\n",
    "    # try to read the taxi zone lookup csv\n",
    "    try:\n",
    "        t_zone = pd.read_csv('data/taxi_zone_lookup.csv') # dataset containing the names of the zones, Borough and Zone\n",
    "    except:\n",
    "        print('taxi zone lookup file not found')\n",
    "    \n",
    "    # data is stored one file per month, 1= Jan - 12=Dec\n",
    "    for i in range(1, 13):\n",
    "        file_name = f'{app}_hourly_{year}_{i}.csv' #No leading zero on month.\n",
    "        file_path = os.path.join(path_to_hourly, file_name)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_name}\")\n",
    "\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # pickup zones\n",
    "    combined_df = combined_df.merge(t_zone[['LocationID','Borough','Zone']], how ='left', left_on='PULocationID_mode', right_on='LocationID')\n",
    "    combined_df.drop(columns=['LocationID'], inplace=True)\n",
    "    combined_df.rename(columns={'Borough':'PULocationBorough','Zone':'PULocationZone'}, inplace=True)\n",
    "\n",
    "    # dropoff zones\n",
    "    combined_df = combined_df.merge(t_zone[['LocationID','Borough','Zone']], how ='left', left_on='DOLocationID_mode', right_on='LocationID')\n",
    "    combined_df.drop(columns=['LocationID'], inplace=True)\n",
    "    combined_df.rename(columns={'Borough':'DOLocationBorough','Zone':'DOLocationZone'}, inplace=True)\n",
    "        # \n",
    "        # combined_df.to_csv(f'data/hourly/{app}_hourly_{year}.csv', index=False)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379500d7-36ea-460a-9a49-69025cd80c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "raw_to_hourly(path_to_raw = 'data/high_volume_raw/', year = '2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b407a38-8e7c-4e83-9dd6-9b0cacf9b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_hourly_df = combine_hourly_data(path_to_hourly = 'data/hourly', app='lyft', year='2020')\n",
    "# lyft_hourly_df['trip_count'].sum() # 36,123,878\n",
    "\n",
    "uber_hourly_df = combine_hourly_data(path_to_hourly = 'data/hourly', app='uber', year='2020')\n",
    "# uber_hourly_df['trip_count'].sum() # 87,339,928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7638879f-2db8-4739-8d5e-a519b02cb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_hourly_df.to_csv('data/hourly/lyft_hourly_2020.csv', index=False)\n",
    "uber_hourly_df.to_csv('data/hourly/uber_hourly_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7257a-d15b-43d2-ae5f-69c5147993de",
   "metadata": {},
   "source": [
    "# 2024 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e483a83-6a20-41f3-b7f9-c54588e28e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows dropped for dataset 1:  -770338\n",
      "Saved to disk 1\n",
      "Num rows dropped for dataset 2:  -1377161\n",
      "Saved to disk 2\n",
      "Num rows dropped for dataset 3:  -853694\n",
      "Saved to disk 3\n",
      "Num rows dropped for dataset 4:  -758993\n",
      "Saved to disk 4\n",
      "Num rows dropped for dataset 5:  -874917\n",
      "Saved to disk 5\n",
      "Num rows dropped for dataset 6:  -1039563\n",
      "Saved to disk 6\n",
      "Num rows dropped for dataset 7:  -888060\n",
      "Saved to disk 7\n",
      "Num rows dropped for dataset 8:  -983788\n",
      "Saved to disk 8\n",
      "Num rows dropped for dataset 9:  -1288341\n",
      "Saved to disk 9\n",
      "Num rows dropped for dataset 10:  -1250207\n",
      "Saved to disk 10\n",
      "Num rows dropped for dataset 11:  -1562148\n",
      "Saved to disk 11\n",
      "Num rows dropped for dataset 12:  -1940439\n",
      "Saved to disk 12\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "raw_to_hourly(path_to_raw = 'data/high_volume_raw/', year = '2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a013e0f-2334-4c1d-b2ab-f85ec529b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_hourly_df = combine_hourly_data(path_to_hourly = 'data/hourly', app='lyft', year='2024')\n",
    "# lyft_hourly_df['trip_count'].sum() # 58,708,695\n",
    "\n",
    "uber_hourly_df = combine_hourly_data(path_to_hourly = 'data/hourly', app='uber', year='2024')\n",
    "# uber_hourly_df['trip_count'].sum() # 167,174,104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "438cc628-e075-489e-82cb-e3946b62d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8783, 28)\n",
      "(8784, 28)\n"
     ]
    }
   ],
   "source": [
    "print(lyft_hourly_df.shape)\n",
    "print(uber_hourly_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "418b809b-4119-4679-8323-cc06b81d25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_hourly_df.to_csv('data/hourly/lyft_hourly_2024.csv', index=False)\n",
    "uber_hourly_df.to_csv('data/hourly/uber_hourly_2024.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:IST707_env]",
   "language": "python",
   "name": "conda-env-IST707_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
