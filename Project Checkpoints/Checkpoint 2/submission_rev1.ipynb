{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0ccc68-ac62-43d1-97ea-ebb265c2fb66",
   "metadata": {},
   "source": [
    "# Rideshare Price Prediction\n",
    "\n",
    "### Team:\n",
    "Marko Masnikosa: mmasniko@syr.edu \n",
    "- GitHub: https://github.com/data11y - POC <br>\n",
    "\n",
    "Dawryn Rosario: darosari@syr.edu\n",
    "- GitHub: https://github.com/darosari\n",
    "\n",
    "Rianne Parker: riparker@syr.edu\n",
    "- GitHub: https://github.com/DatawithParker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f94b5-5a13-4db0-bc1d-2698f5d06f12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Overview\n",
    "We are trying to predict hourly pricing for Lyft and Uber trips in New York City. Our approach involves looking to the Taxi and Limousine Commission of New York City data for trip information, weather data, and MTA subway trip data for alternative travel options. With multimodal transport options considered, we hope to be able to provide a model that can inform users to which mode of travel would be more efficient at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a181c4-d325-43c4-b4d9-965a7678d5a2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b821cdf9-4a08-4a91-9f94-90162c7291df",
   "metadata": {},
   "source": [
    "### TLC Data  \n",
    "Taxi and Limousine Commission of NYC data includes trip level data for the entire year. Data is available for Yellow Cabs, Green Cabs (more efficient), For Hire Vehicles, and High-Volume For Hire Vehicles. We focused on the High Volume data as this includes Lyft and Uber trips, as well as smaller rideshare platforms. Data is broken up by year, vehicle type, and month and is available as parquet files. The data is centered around taxi zones which will be explained later. [TLC data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) <p> Data Preprocessing:\n",
    "* **Data Collection**: Data was collected for the year of 2020 and 2024. The files are large (200MB+ each) so filtering and aggregation was applied.\n",
    "* **Data Filtering**: The High Volume data included several rideshare app platforms. This was filtered down to just Uber and Lyft, which made up the bulk of the data regardless. There were several features that were dropped for having low variance or high emptiness. Trips where the components of the trip cost were less than the driver pay were dropped, these rows indicated that the driver was paid more than what the rider was charged which is not normally the case.\n",
    "* **Data Aggregation**: The raw data for each year for just the two apps is over 200 million rows per year. This amount of data was too large to easily handle and was thus aggregated to hourly data split across apps. The categorical features such as pickup location and drop off location were aggregated to the most frequent of that hour. Numerical features such as trip distance were aggregated to the mean and sum of that hour.\n",
    "* **Taxi Zones**: The data is centered around taxi zones which are zones created by the TLC. Here is a map of the taxi zones in NYC: <img src='pictures/nyc_taxi_zones_satellite_overlay.png' width = \"500\"/>\n",
    "\n",
    "\n",
    "Many data exploration questions were asked and examined. Some interesting findings include the following.\n",
    "* Connections: In the data, pickups are happening across a wide area of taxi zones, but the drop offs are more concentrated to specific zones or are headed out of NYC. Not shown in this image but in more granular exploration showed some taxi zones were serviced much more by one app over another. <img src='pictures/nyc_rideshare_pickup_and_dropoffs_2024.png' width = \"500\" />\n",
    "\n",
    "* App Dominance: Uber is significantly more used in NYC than Lyft. It would be interesting to have access to the driver payout strucure between the two apps to see why. <img src='pictures/nyc_rideshare_moving_avg_trip_volumes_2024.png' width = \"500\" />\n",
    "\n",
    "* Zone Connections: Where are people who are picked up in one zone getting dropped off? It turns out they don't typically leave their taxi zones. This is excluding airport pickups and dropoffs. <img src='pictures/uber_lyft_connections_top_5_2024.png' width = \"500\" />\n",
    "\n",
    "* Tips: Lyft riders are more generous than Uber riders when it comes to tipping. <img src='pictures/rider_generosity.png' width = \"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca47cdb",
   "metadata": {},
   "source": [
    "### MTA Delays Data EDA\n",
    "#### 1. Data Loading & Initial Exploration\n",
    "\n",
    "    In this section, I load the raw MTA Delays dataset and perform an initial inspection of the structure, column names, and datatypes. The goal is to understand what information is available, identify any immediate issues (e.g., null values or formatting problems), and prepare for further preprocessing.\n",
    "\n",
    "Some questions that can be asnwered:\n",
    "- What are the key columns in this dataset?\n",
    "- What is the size of the dataset?\n",
    "- Are there any obvious missing or corrupted values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73a4511",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspaces/SU-IST707-Group_Project/Project Checkpoints/Checkpoint 2/original_MTA_Subway_Trains_Delayed__Beginning_2020_20250303.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# link for MTA DELAYS: https://data.ny.gov/Transportation/MTA-Subway-Trains-Delayed-Beginning-2020/wx2t-qtaz/about_data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m delays_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/workspaces/SU-IST707-Group_Project/Project Checkpoints/Checkpoint 2/original_MTA_Subway_Trains_Delayed__Beginning_2020_20250303.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#when the MTA DELAYS file is local\u001b[39;00m\n\u001b[32m      5\u001b[39m delays_df.head()\u001b[38;5;66;03m#showing first few rows\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspaces/SU-IST707-Group_Project/Project Checkpoints/Checkpoint 2/original_MTA_Subway_Trains_Delayed__Beginning_2020_20250303.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# link for MTA DELAYS: https://data.ny.gov/Transportation/MTA-Subway-Trains-Delayed-Beginning-2020/wx2t-qtaz/about_data\n",
    "delays_df = pd.read_csv(\"/workspaces/SU-IST707-Group_Project/Project Checkpoints/Checkpoint 2/original_MTA_Subway_Trains_Delayed__Beginning_2020_20250303.csv\") #when the MTA DELAYS file is local\n",
    "delays_df.head()#showing first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ae774",
   "metadata": {},
   "source": [
    "#### 2. Exploratory Data Analysis (EDA) ‚Äì MTA Delays\n",
    "\n",
    "    This section explores trends and distributions in the subway delay data to better understand temporal patterns, types of delays, and how delays vary across subway lines.\n",
    "\n",
    "I aim to answer:\n",
    "- What are the most common types of delays?\n",
    "- Are certain subway lines more frequently delayed?\n",
    "- Do delays occur more often at certain times or days?\n",
    "- Are delays increasing or decreasing over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9fd2d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MTA_Subway_Trains_Delayed__Beginning_2020_20250331.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#load dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m delays_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMTA_Subway_Trains_Delayed__Beginning_2020_20250331.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Basic structure\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müßæ Dataset Overview:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'MTA_Subway_Trains_Delayed__Beginning_2020_20250331.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load dataset\n",
    "delays_df = pd.read_csv(\"MTA_Subway_Trains_Delayed__Beginning_2020_20250331.csv\")\n",
    "\n",
    "# Basic structure\n",
    "print(\"üßæ Dataset Overview:\")\n",
    "print(\"-\" * 50)\n",
    "print(delays_df.info())\n",
    "print(\"\\nüîç Null Values:\")\n",
    "print(delays_df.isnull().sum())\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nüìÑ First 5 Rows:\")\n",
    "display(delays_df.head())\n",
    "\n",
    "# Top Delay Causes\n",
    "print(\"\\nüìå Top Reporting Categories:\")\n",
    "print(delays_df['reporting_category'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nüìå Top Specific Subcategories:\")\n",
    "print(delays_df['subcategory'].value_counts().head(10))\n",
    "\n",
    "\n",
    "# Most Affected Lines\n",
    "print(\"\\nüöá Most Affected Subway Lines:\")\n",
    "print(delays_df['line'].value_counts().head(10))\n",
    "\n",
    "# Convert date column\n",
    "delays_df['month'] = pd.to_datetime(delays_df['month'], errors='coerce')\n",
    "\n",
    "# Extract temporal features\n",
    "delays_df['Year'] = delays_df['month'].dt.year\n",
    "delays_df['Month'] = delays_df['month'].dt.month\n",
    "delays_df['Weekday'] = delays_df['month'].dt.day_name()\n",
    "\n",
    "# Plot delay count per year\n",
    "plt.figure(figsize=(8, 4))\n",
    "delays_df['Year'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title(\"üóìÔ∏è Delay Reports Per Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Delay Reports\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8636d8",
   "metadata": {},
   "source": [
    " #### EDA Summary ‚Äì MTA Subway Delays\n",
    "\n",
    "- The dataset contains **40,503** entries and **7 columns**, covering subway delays across multiple lines and divisions.\n",
    "- The most frequent **reporting categories** are:\n",
    "  - Infrastructure & Equipment\n",
    "  - Crew Availability\n",
    "  - External Factors\n",
    "- Common specific causes include door-related issues, braking, and debris on tracks.\n",
    "- Only the `subcategory` column has missing values (~5.5% of records).\n",
    "- Delay frequency is reported by month and has been converted to datetime format.\n",
    "- Additional features (`Year`, `Month`, `Weekday`) were extracted to support temporal analysis.\n",
    "- A time series plot shows variation in delays across years, providing insight into longer-term trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc1e07",
   "metadata": {},
   "source": [
    "#### 3. Data Cleaning & Feature Engineering ‚Äì MTA Delays\n",
    "\n",
    "    This section handles missing values, standardizes categorical text data, and prepares the dataset for downstream modeling. I focus on ensuring consistency in categorical fields and creating useful features from raw columns.\n",
    "\n",
    "Key steps:\n",
    "- Fill or tag missing values in `subcategory`\n",
    "- Normalize text fields to lowercase for consistency\n",
    "- Ensure all datetime fields are usable\n",
    "- Prepare for joins with other datasets (e.g., weather, ridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd5658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Cleaned Columns Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>division</th>\n",
       "      <th>line</th>\n",
       "      <th>reporting_category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>day_type_label</th>\n",
       "      <th>delays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>a division</td>\n",
       "      <td>1</td>\n",
       "      <td>crew availability</td>\n",
       "      <td>crew availability</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>a division</td>\n",
       "      <td>1</td>\n",
       "      <td>external factors</td>\n",
       "      <td>external debris on roadbed</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>a division</td>\n",
       "      <td>1</td>\n",
       "      <td>infrastructure &amp; equipment</td>\n",
       "      <td>braking</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>a division</td>\n",
       "      <td>1</td>\n",
       "      <td>infrastructure &amp; equipment</td>\n",
       "      <td>door-related</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>a division</td>\n",
       "      <td>1</td>\n",
       "      <td>infrastructure &amp; equipment</td>\n",
       "      <td>fire, smoke, debris</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month    division line          reporting_category  \\\n",
       "0 2024-12-01  a division    1           crew availability   \n",
       "1 2024-12-01  a division    1            external factors   \n",
       "2 2024-12-01  a division    1  infrastructure & equipment   \n",
       "3 2024-12-01  a division    1  infrastructure & equipment   \n",
       "4 2024-12-01  a division    1  infrastructure & equipment   \n",
       "\n",
       "                  subcategory day_type_label  delays  \n",
       "0           crew availability        Weekday      83  \n",
       "1  external debris on roadbed        Weekday       4  \n",
       "2                     braking        Weekday      37  \n",
       "3                door-related        Weekday      34  \n",
       "4         fire, smoke, debris        Weekday      37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fill missing values in subcategory\n",
    "delays_df['subcategory'] = delays_df['subcategory'].fillna('Unknown')\n",
    "\n",
    "#standardize string columns (lowercase, strip whitespace)\n",
    "for col in ['division', 'line', 'reporting_category', 'subcategory']:\n",
    "    delays_df[col] = delays_df[col].str.lower().str.strip()\n",
    "\n",
    "#optional: create a 'day_type_label' if needed\n",
    "day_type_map = {\n",
    "    1: 'Weekday',\n",
    "    2: 'Saturday',\n",
    "    3: 'Sunday/Holiday'\n",
    "}\n",
    "delays_df['day_type_label'] = delays_df['day_type'].map(day_type_map)\n",
    "\n",
    "#check result\n",
    "print(\"üîç Cleaned Columns Preview:\")\n",
    "display(delays_df[['month', 'division', 'line', 'reporting_category', 'subcategory', 'day_type_label', 'delays']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1056ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Final DataFrame Structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40503 entries, 0 to 40502\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   month               40503 non-null  datetime64[ns]\n",
      " 1   division            40503 non-null  object        \n",
      " 2   line                40503 non-null  object        \n",
      " 3   day_type            40503 non-null  int64         \n",
      " 4   reporting_category  40503 non-null  object        \n",
      " 5   subcategory         40503 non-null  object        \n",
      " 6   delays              40503 non-null  int64         \n",
      " 7   Year                40503 non-null  int32         \n",
      " 8   Month               40503 non-null  int32         \n",
      " 9   Weekday             40503 non-null  object        \n",
      " 10  day_type_label      40503 non-null  object        \n",
      "dtypes: datetime64[ns](1), int32(2), int64(2), object(6)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "\n",
      "üìå Unique Reporting Categories:\n",
      "reporting_category\n",
      "infrastructure & equipment    19744\n",
      "police & medical               6864\n",
      "planned row work               6187\n",
      "external factors               2833\n",
      "crew availability              2463\n",
      "operating conditions           2412\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìå Unique Subcategories (Top 10):\n",
      "subcategory\n",
      "public conduct, crime, police response    2547\n",
      "crew availability                         2463\n",
      "other - sig                               2421\n",
      "subways maintenance                       2416\n",
      "unknown                                   2249\n",
      "sick/injured customer                     2242\n",
      "service delivery                          2239\n",
      "persons on roadbed                        2075\n",
      "other - ce                                1981\n",
      "rail and roadbed                          1976\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üöá Unique Subway Lines (Top 10):\n",
      "line\n",
      "a    2294\n",
      "n    2294\n",
      "2    2237\n",
      "d    2168\n",
      "f    2154\n",
      "q    2154\n",
      "r    2115\n",
      "4    2089\n",
      "6    2017\n",
      "1    1997\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìÜ Date Range:\n",
      "From 2020-01-01 to 2024-12-01\n",
      "\n",
      "üß™ Sample of Temporal Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34765</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39073</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10809</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           month  Year  Month    Weekday\n",
       "9326  2023-11-01  2023     11  Wednesday\n",
       "4609  2024-06-01  2024      6   Saturday\n",
       "34765 2020-10-01  2020     10   Thursday\n",
       "39073 2020-03-01  2020      3     Sunday\n",
       "10809 2023-09-01  2023      9     Friday"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Day Type Mapping Preview:\n",
      "day_type_label\n",
      "Weekday     24076\n",
      "Saturday    16427\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show cleaned DataFrame structure\n",
    "print(\"üßæ Final DataFrame Structure:\")\n",
    "print(delays_df.info())\n",
    "\n",
    "# Check unique values in key categorical columns\n",
    "print(\"\\nüìå Unique Reporting Categories:\")\n",
    "print(delays_df['reporting_category'].value_counts())\n",
    "\n",
    "print(\"\\nüìå Unique Subcategories (Top 10):\")\n",
    "print(delays_df['subcategory'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nüöá Unique Subway Lines (Top 10):\")\n",
    "print(delays_df['line'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nüìÜ Date Range:\")\n",
    "print(f\"From {delays_df['month'].min().date()} to {delays_df['month'].max().date()}\")\n",
    "\n",
    "# Check if datetime features exist and look good\n",
    "print(\"\\nüß™ Sample of Temporal Features:\")\n",
    "display(delays_df[['month', 'Year', 'Month', 'Weekday']].sample(5))\n",
    "\n",
    "# Check if day_type_label mapping worked\n",
    "print(\"\\nüìÖ Day Type Mapping Preview:\")\n",
    "print(delays_df['day_type_label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcfad2",
   "metadata": {},
   "source": [
    "### Weather Data  \n",
    "\n",
    " Weather data in this project is used to identify how conditions affect rideshare pricing in NYC. It helps capture demand spikes and travel delays caused by adverse weather. This allows for more accurate fare predictions and better planning for both riders and service providers.\n",
    "\n",
    "* **Source**: Visual Crossing \n",
    "* **Website**: https://www.visualcrossing.com/\n",
    "* **Descriptions**: Visual Crossing is a leading provider of weather data and enterprise analysis tools to data scientists, business analysts, professionals, and academics. Visual Crossing aims to provide accurate weather data and forecasts by combining data from various sources, including ground-based weather stations, satellites, and radar, and using statistical climate modeling.\n",
    "\n",
    "<img src=\"/workspaces/SU-IST707-Group_Project/Project Checkpoints/Checkpoint 2/PoweredByVC-WeatherLogo-RoundedRect.png\" alt=\"Alt Text\" width=\"250\" height=\"75\">\n",
    "\n",
    " \n",
    "#### Data Processing\n",
    "\n",
    "* **Data Collection**: NYC Weather Data was collected for the year of 1-1-2020 and 12-31-2024. The file is 2MB. It was pulled via query from Visual Crossings. \n",
    "* **Data Exploration**: The initial exploration focused on understanding the dataset structure, inspecting data types, and examining the distribution of weather variables such as temperature, precipitation, and windspeed. Special attention was given to the datetime column to ensure consistent hourly intervals throughout the time series.\n",
    "* **Data Filtering and Cleaning**: Non-essential columns were removed to focus the analysis on key weather-related variables. The dataset was filtered to retain only hourly observations, and duplicate or invalid entries were excluded to maintain data quality.\n",
    "    + **Columns removed**: name, dew, humidity, precipprob, snowdepth, windgust, winddir, sealevelpressure, solarradiation, solarenergy, severerisk, icon, stations, preciptype.\n",
    "    + **Remaining Columns**: datetime, temp, feelslike, precip, snow, windspeed, cloudcover, visibility, uvindex, conditions\n",
    "    + **DateTime Check**: Missing hourly records‚Äîprimarily caused by daylight saving time transitions‚Äîwere detected by comparing the dataset's timestamps against a complete hourly range. These missing records were then filled by averaging the values from the hour before and after, ensuring continuity in the time series.\n",
    "        - Timestamps added to Dataframe: \"2020-03-08 02:00:00\", \"2021-03-14 02:00:00\", \"2022-03-13 02:00:00\", \"2023-03-12 02:00:00\",\"2024-03-10 02:00:00\"\n",
    "    + **'Conditions' Column Value Encoding**: The column is a categorical representation of combined weather conditions, encoded as numerical values to simplify analysis and modeling. Below is the mapping used:\n",
    "\n",
    "        - **0** ‚Äî Overcast  \n",
    "        - **1** ‚Äî Partially cloudy  \n",
    "        - **2** ‚Äî Clear  \n",
    "        - **3** ‚Äî Rain, Overcast  \n",
    "        - **4** ‚Äî Rain, Partially cloudy  \n",
    "        - **5** ‚Äî Snow, Rain, Partially cloudy  \n",
    "        - **6** ‚Äî Snow, Rain, Overcast  \n",
    "        - **7** ‚Äî Snow, Overcast  \n",
    "        - **8** ‚Äî Snow, Partially cloudy  \n",
    "        - **9** ‚Äî Rain  \n",
    "        - **10** ‚Äî Snow  \n",
    "        - **11** ‚Äî Snow, Rain  \n",
    "    + **Dataframe shape**: 43,848 rows x 10 columns\n",
    "\n",
    "#### NYC Weather Visual (2020-2024)\n",
    "\n",
    "Temperatures steadily rise from January to July, peaking in the summer months before gradually declining through December. While the overall pattern is consistent year-to-year, slight variations appear ‚Äî for example, 2023 had a warmer early spring compared to other years. \n",
    "\n",
    "<img src=\"/workspaces/SU-IST707-Group_Project/Project Checkpoints/Checkpoint 2/Weather plot.png\" alt=\"Alt Text\" width=\"800\" height=\"480\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f24202",
   "metadata": {},
   "source": [
    "### MTA Ridership Data\n",
    "MTA ridership data is used to analyze transit trends and understand how public transportation usage changed over time, especially during and after the COVID-19 pandemic. It provides insight into recovery patterns, demand for various transportation modes, and infrastructure usage across NYC. This information is crucial for planning service levels, evaluating operational efficiency, and informing transportation policy decisions.\n",
    "\n",
    "* **Source**: NYC Open Data ‚Äì MTA Ridership (Daily)\n",
    "\n",
    "* **Website**: https://data.ny.gov/Transportation/MTA-Daily-Ridership-Data-2020-2025/vxuj-8kew/about_data\n",
    "\n",
    "* **Descriptions**: This dataset contains daily estimated ridership counts across multiple modes of MTA transportation in NYC. It includes subways, buses, Long Island Railroad (LIRR), Metro-North, Access-A-Ride, bridges and tunnels, and the Staten Island Railway. The dataset was made available to support transparency and inform stakeholders about mobility trends in NYC during and following the pandemic.\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "* **Data Collection**: MTA ridership data was collected between 2020-03-01 and 2025-01-09. The raw file was downloaded as a CSV from NYC Open Data. It includes 5 years of daily ridership estimates across several transportation systems.\n",
    "\n",
    "* **Data Exploration**: The initial exploration involved reviewing column names, inspecting data types, and identifying the presence of missing or duplicate date records. Columns were checked for consistency and numerical values were verified for each ridership metric.\n",
    "\n",
    "* **Data Filtering and Cleaning**: All columns except the Date column were converted to float64 to ensure numerical consistency for analysis. The Date column was converted to a proper datetime format for easy resampling and time-based indexing. Duplicate date entries were removed, and missing dates within the 2020‚Äì2024 range were identified by comparing against a complete date range. Any missing dates were added with null values for interpolation or handling in further analysis.\n",
    "\n",
    "* **NA Handling**: Potential missing values were inspected and none were identified. \n",
    "\n",
    "* **Date Check**: Full coverage was confirmed for the date range 2020-03-01 to 2025-01-09. The complete range includes 1,776 days.\n",
    "\n",
    "* **Dataframe shape after cleaning**: 1,776 rows x 15 columns\n",
    "\n",
    "#### MTA Ridership - Monthly (2020-2024)\n",
    "\n",
    "Subway ridership dropped sharply in early 2020 due to the pandemic but steadily recovered, peaking by 2024. Bus ridership also declined early but stabilized more quickly, while services like Access-A-Ride and Staten Island Railway maintained relatively low, flat usage. Bridges and Tunnels traffic steadily increased, suggesting more reliance on personal vehicles post-pandemic.\n",
    "\n",
    "<img src=\"/workspaces/SU-IST707-Group_Project/Project Checkpoints/Checkpoint 2/MTA Daily Ridership.png\" alt=\"Alt Text\" width=\"800\" height=\"480\">\n",
    "\n",
    "#### MTA Ridership - Weekend vs Weekday (2020-2024)\n",
    "\n",
    "Ridership dropped sharply in early 2020 due to the COVID-19 pandemic but steadily recovered over time. Weekday ridership consistently remained higher than weekend levels, reflecting commuter travel patterns. Both lines show gradual growth with some seasonal dips, indicating partial normalization of public transit usage by 2024.\n",
    "\n",
    "<img src=\"/workspaces/SU-IST707-Group_Project/Project Checkpoints/Checkpoint 2/MTA Ridership - Weekend v. Weekday.png\" alt=\"Alt Text\" width=\"800\" height=\"480\">\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
